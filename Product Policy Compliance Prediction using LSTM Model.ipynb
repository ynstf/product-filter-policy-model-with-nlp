{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8c635a",
   "metadata": {},
   "source": [
    "# manipulation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f6ff4",
   "metadata": {},
   "source": [
    "## read and show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "77b3cde9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>marked_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>sizes</th>\n",
       "      <th>product_link</th>\n",
       "      <th>img_link</th>\n",
       "      <th>product_tag</th>\n",
       "      <th>brand_tag</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>discount_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Croc Textured Two Fold Wallet</td>\n",
       "      <td>Lino Perros</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1295</td>\n",
       "      <td>828</td>\n",
       "      <td>Onesize</td>\n",
       "      <td>wallets/lino-perros/lino-perros-women-peach-co...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>wallets</td>\n",
       "      <td>lino-perros</td>\n",
       "      <td>467</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Men Striped Sliders</td>\n",
       "      <td>Mast &amp; Harbour</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1299</td>\n",
       "      <td>584</td>\n",
       "      <td>UK6,UK7,UK8,UK9,UK10,UK11</td>\n",
       "      <td>flip-flops/mast--harbour/mast--harbour-men-nav...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>flip-flops</td>\n",
       "      <td>mast--harbour</td>\n",
       "      <td>715</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Printed A-line Kurta</td>\n",
       "      <td>Biba</td>\n",
       "      <td>4.3</td>\n",
       "      <td>66</td>\n",
       "      <td>1999</td>\n",
       "      <td>1599</td>\n",
       "      <td>S,M,L,XL,XXL,3XL</td>\n",
       "      <td>kurtas/biba/biba-women-off-white--black-printe...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>kurtas</td>\n",
       "      <td>biba</td>\n",
       "      <td>400</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Girls Floral Printed T-shirt</td>\n",
       "      <td>Anthrilo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "      <td>539</td>\n",
       "      <td>7-8Y,8-9Y,9-10Y</td>\n",
       "      <td>tshirts/anthrilo/anthrilo-girls-white-floral-p...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>tshirts</td>\n",
       "      <td>anthrilo</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women Printed Kurta with Skirt</td>\n",
       "      <td>FASHION DWAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2899</td>\n",
       "      <td>2899</td>\n",
       "      <td>S,M,L,XL</td>\n",
       "      <td>kurta-sets/fashion-dwar/fashion-dwar-women-mul...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>kurta-sets</td>\n",
       "      <td>fashion-dwar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Floral Cotton Maxi Dress</td>\n",
       "      <td>Vishudh</td>\n",
       "      <td>4.1</td>\n",
       "      <td>800</td>\n",
       "      <td>4349</td>\n",
       "      <td>1826</td>\n",
       "      <td>S,M,L,XL,XXL</td>\n",
       "      <td>dresses/vishudh/vishudh-rust-brown-floral-prin...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>dresses</td>\n",
       "      <td>vishudh</td>\n",
       "      <td>2523</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fitted Crop Top</td>\n",
       "      <td>Tokyo Talkies</td>\n",
       "      <td>4.4</td>\n",
       "      <td>210</td>\n",
       "      <td>499</td>\n",
       "      <td>249</td>\n",
       "      <td>S,M,L,XL</td>\n",
       "      <td>tops/tokyo-talkies/tokyo-talkies-pink-fitted-c...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>tops</td>\n",
       "      <td>tokyo-talkies</td>\n",
       "      <td>250</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Men Mesh Running Shoes</td>\n",
       "      <td>Woakers</td>\n",
       "      <td>3.4</td>\n",
       "      <td>591</td>\n",
       "      <td>3125</td>\n",
       "      <td>687</td>\n",
       "      <td>UK6,UK7,UK8,UK9,UK10</td>\n",
       "      <td>sports-shoes/woakers/woakers-men-white--orange...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>sports-shoes</td>\n",
       "      <td>woakers</td>\n",
       "      <td>2438</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Men Checked Pullover</td>\n",
       "      <td>Roadster</td>\n",
       "      <td>4.3</td>\n",
       "      <td>528</td>\n",
       "      <td>1999</td>\n",
       "      <td>999</td>\n",
       "      <td>S,M,L,XL</td>\n",
       "      <td>sweaters/roadster/the-roadster-lifestyle-co-me...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>sweaters</td>\n",
       "      <td>roadster</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Girls Cotton Jersey Top</td>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16</td>\n",
       "      <td>599</td>\n",
       "      <td>599</td>\n",
       "      <td>8-10Y,10-12Y,12-14Y,14-15Y</td>\n",
       "      <td>tops/hm/hm-girls-pink-cotton-jersey-top/169299...</td>\n",
       "      <td>https://assets.myntassets.com/dpr_2,q_60,w_210...</td>\n",
       "      <td>tops</td>\n",
       "      <td>hm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     product_name      brand_name  rating  rating_count  \\\n",
       "0   Croc Textured Two Fold Wallet     Lino Perros     0.0             0   \n",
       "1             Men Striped Sliders  Mast & Harbour     4.0            76   \n",
       "2            Printed A-line Kurta            Biba     4.3            66   \n",
       "3    Girls Floral Printed T-shirt        Anthrilo     0.0             0   \n",
       "4  Women Printed Kurta with Skirt    FASHION DWAR     0.0             0   \n",
       "5        Floral Cotton Maxi Dress         Vishudh     4.1           800   \n",
       "6                 Fitted Crop Top   Tokyo Talkies     4.4           210   \n",
       "7          Men Mesh Running Shoes         Woakers     3.4           591   \n",
       "8            Men Checked Pullover        Roadster     4.3           528   \n",
       "9         Girls Cotton Jersey Top             H&M     4.2            16   \n",
       "\n",
       "   marked_price  discounted_price                       sizes  \\\n",
       "0          1295               828                     Onesize   \n",
       "1          1299               584   UK6,UK7,UK8,UK9,UK10,UK11   \n",
       "2          1999              1599            S,M,L,XL,XXL,3XL   \n",
       "3           599               539             7-8Y,8-9Y,9-10Y   \n",
       "4          2899              2899                    S,M,L,XL   \n",
       "5          4349              1826                S,M,L,XL,XXL   \n",
       "6           499               249                    S,M,L,XL   \n",
       "7          3125               687        UK6,UK7,UK8,UK9,UK10   \n",
       "8          1999               999                    S,M,L,XL   \n",
       "9           599               599  8-10Y,10-12Y,12-14Y,14-15Y   \n",
       "\n",
       "                                        product_link  \\\n",
       "0  wallets/lino-perros/lino-perros-women-peach-co...   \n",
       "1  flip-flops/mast--harbour/mast--harbour-men-nav...   \n",
       "2  kurtas/biba/biba-women-off-white--black-printe...   \n",
       "3  tshirts/anthrilo/anthrilo-girls-white-floral-p...   \n",
       "4  kurta-sets/fashion-dwar/fashion-dwar-women-mul...   \n",
       "5  dresses/vishudh/vishudh-rust-brown-floral-prin...   \n",
       "6  tops/tokyo-talkies/tokyo-talkies-pink-fitted-c...   \n",
       "7  sports-shoes/woakers/woakers-men-white--orange...   \n",
       "8  sweaters/roadster/the-roadster-lifestyle-co-me...   \n",
       "9  tops/hm/hm-girls-pink-cotton-jersey-top/169299...   \n",
       "\n",
       "                                            img_link   product_tag  \\\n",
       "0  https://assets.myntassets.com/dpr_2,q_60,w_210...       wallets   \n",
       "1  https://assets.myntassets.com/dpr_2,q_60,w_210...    flip-flops   \n",
       "2  https://assets.myntassets.com/dpr_2,q_60,w_210...        kurtas   \n",
       "3  https://assets.myntassets.com/dpr_2,q_60,w_210...       tshirts   \n",
       "4  https://assets.myntassets.com/dpr_2,q_60,w_210...    kurta-sets   \n",
       "5  https://assets.myntassets.com/dpr_2,q_60,w_210...       dresses   \n",
       "6  https://assets.myntassets.com/dpr_2,q_60,w_210...          tops   \n",
       "7  https://assets.myntassets.com/dpr_2,q_60,w_210...  sports-shoes   \n",
       "8  https://assets.myntassets.com/dpr_2,q_60,w_210...      sweaters   \n",
       "9  https://assets.myntassets.com/dpr_2,q_60,w_210...          tops   \n",
       "\n",
       "       brand_tag  discount_amount  discount_percent  \n",
       "0    lino-perros              467                36  \n",
       "1  mast--harbour              715                55  \n",
       "2           biba              400                20  \n",
       "3       anthrilo               60                10  \n",
       "4   fashion-dwar                0                 0  \n",
       "5        vishudh             2523                58  \n",
       "6  tokyo-talkies              250                50  \n",
       "7        woakers             2438                78  \n",
       "8       roadster             1000                50  \n",
       "9             hm                0                 0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yes = pd.read_csv('data.csv')\n",
    "df_yes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "68817510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yes[\"Name of Product\"] = df_yes[\"product_name\"]\n",
    "df_yes[\"Is Accepted Policy\"] = \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cb5a26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yes = df_yes.loc[:,[\"Name of Product\",\"Is Accepted Policy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0aadff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Croc Textured Two Fold Wallet</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Men Striped Sliders</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Printed A-line Kurta</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Girls Floral Printed T-shirt</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women Printed Kurta with Skirt</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168024</th>\n",
       "      <td>Ethnic Motifs Kaftan Dress</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168025</th>\n",
       "      <td>Leather Wedge Sandals with Tassels</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168026</th>\n",
       "      <td>Leather Wedge Pumps</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168027</th>\n",
       "      <td>V015 Professional Hair Trimmer</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168028</th>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168029 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name of Product Is Accepted Policy\n",
       "0            Croc Textured Two Fold Wallet                Yes\n",
       "1                      Men Striped Sliders                Yes\n",
       "2                     Printed A-line Kurta                Yes\n",
       "3             Girls Floral Printed T-shirt                Yes\n",
       "4           Women Printed Kurta with Skirt                Yes\n",
       "...                                    ...                ...\n",
       "168024          Ethnic Motifs Kaftan Dress                Yes\n",
       "168025  Leather Wedge Sandals with Tassels                Yes\n",
       "168026                 Leather Wedge Pumps                Yes\n",
       "168027      V015 Professional Hair Trimmer                Yes\n",
       "168028                Women Open Toe Flats                Yes\n",
       "\n",
       "[168029 rows x 2 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ef0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ee90ad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_0022DWKP</td>\n",
       "      <td>Had a dream i got raped last night. By a guy i...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_00395QYM</td>\n",
       "      <td>he thought the word raped means sex and told m...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_003EOSSF</td>\n",
       "      <td>She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_004BBHOD</td>\n",
       "      <td>I was sexually abused for 3 years at age 4 to ...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_004F7516</td>\n",
       "      <td>Chessy Prout can do better by telling the trut...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39645</th>\n",
       "      <td>ID_ZZTLP2L5</td>\n",
       "      <td>ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39646</th>\n",
       "      <td>ID_ZZXB10M6</td>\n",
       "      <td>So you’re telling me Emmanuel Macron was groom...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39647</th>\n",
       "      <td>ID_ZZY8B7FJ</td>\n",
       "      <td>My wife regularly beats me, I get dirty slaps ...</td>\n",
       "      <td>Physical_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39648</th>\n",
       "      <td>ID_ZZYAFD8L</td>\n",
       "      <td>Me: Hey babe! Police officer boyfriend: is tha...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39649</th>\n",
       "      <td>ID_ZZZ8QEKT</td>\n",
       "      <td>“I will take accountability if you think it’s ...</td>\n",
       "      <td>sexual_violence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39650 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tweet_ID                                              tweet  \\\n",
       "0      ID_0022DWKP  Had a dream i got raped last night. By a guy i...   \n",
       "1      ID_00395QYM  he thought the word raped means sex and told m...   \n",
       "2      ID_003EOSSF  She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...   \n",
       "3      ID_004BBHOD  I was sexually abused for 3 years at age 4 to ...   \n",
       "4      ID_004F7516  Chessy Prout can do better by telling the trut...   \n",
       "...            ...                                                ...   \n",
       "39645  ID_ZZTLP2L5  ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...   \n",
       "39646  ID_ZZXB10M6  So you’re telling me Emmanuel Macron was groom...   \n",
       "39647  ID_ZZY8B7FJ  My wife regularly beats me, I get dirty slaps ...   \n",
       "39648  ID_ZZYAFD8L  Me: Hey babe! Police officer boyfriend: is tha...   \n",
       "39649  ID_ZZZ8QEKT  “I will take accountability if you think it’s ...   \n",
       "\n",
       "                    type  \n",
       "0        sexual_violence  \n",
       "1        sexual_violence  \n",
       "2        sexual_violence  \n",
       "3        sexual_violence  \n",
       "4        sexual_violence  \n",
       "...                  ...  \n",
       "39645    sexual_violence  \n",
       "39646    sexual_violence  \n",
       "39647  Physical_violence  \n",
       "39648    sexual_violence  \n",
       "39649    sexual_violence  \n",
       "\n",
       "[39650 rows x 3 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_no = pd.read_csv('train.csv')\n",
    "df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f7aeb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no[\"Name of Product\"] = df_no[\"tweet\"]\n",
    "df_no[\"Is Accepted Policy\"] = \"No\"\n",
    "df_no = df_no.loc[:,[\"Name of Product\",\"Is Accepted Policy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a9d389f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Had a dream i got raped last night. By a guy i...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he thought the word raped means sex and told m...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was sexually abused for 3 years at age 4 to ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chessy Prout can do better by telling the trut...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39645</th>\n",
       "      <td>ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39646</th>\n",
       "      <td>So you’re telling me Emmanuel Macron was groom...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39647</th>\n",
       "      <td>My wife regularly beats me, I get dirty slaps ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39648</th>\n",
       "      <td>Me: Hey babe! Police officer boyfriend: is tha...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39649</th>\n",
       "      <td>“I will take accountability if you think it’s ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39650 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name of Product Is Accepted Policy\n",
       "0      Had a dream i got raped last night. By a guy i...                 No\n",
       "1      he thought the word raped means sex and told m...                 No\n",
       "2      She NOT TALKING TO ME I WAS RAPED BY 2 MEN 1 M...                 No\n",
       "3      I was sexually abused for 3 years at age 4 to ...                 No\n",
       "4      Chessy Prout can do better by telling the trut...                 No\n",
       "...                                                  ...                ...\n",
       "39645  ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...                 No\n",
       "39646  So you’re telling me Emmanuel Macron was groom...                 No\n",
       "39647  My wife regularly beats me, I get dirty slaps ...                 No\n",
       "39648  Me: Hey babe! Police officer boyfriend: is tha...                 No\n",
       "39649  “I will take accountability if you think it’s ...                 No\n",
       "\n",
       "[39650 rows x 2 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d57a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2137a302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra-Thin Gaming Laptop with RGB Backlit Keyb...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deluxe Espresso Machine with Integrated Milk F...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Running Shoes with Responsive Cushion...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latest iPhone Pro Max with Triple-Camera Syste...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Next-Gen Gaming Console with 4K Graphics and E...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Captivating Romantic Novel Set in the Enchanti...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Realistic Toy Sniper Rifle for Outdoor Shootin...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breathtaking Action Movie Marathon in 4K Ultra...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Organic Herbal Infusion Collection for Relaxat...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smart Fitness Tracker with ECG and Blood Oxyge...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name of Product Is Accepted Policy\n",
       "0  Ultra-Thin Gaming Laptop with RGB Backlit Keyb...                Yes\n",
       "1  Deluxe Espresso Machine with Integrated Milk F...                Yes\n",
       "2  Advanced Running Shoes with Responsive Cushion...                Yes\n",
       "3  Latest iPhone Pro Max with Triple-Camera Syste...                Yes\n",
       "4  Next-Gen Gaming Console with 4K Graphics and E...                Yes\n",
       "5  Captivating Romantic Novel Set in the Enchanti...                 No\n",
       "6  Realistic Toy Sniper Rifle for Outdoor Shootin...                 No\n",
       "7  Breathtaking Action Movie Marathon in 4K Ultra...                Yes\n",
       "8  Organic Herbal Infusion Collection for Relaxat...                 No\n",
       "9  Smart Fitness Tracker with ECG and Blood Oxyge...                Yes"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.txt')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ea4678d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames vertically\n",
    "data = pd.concat([df, df_yes, df_no], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "017fddaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra-Thin Gaming Laptop with RGB Backlit Keyb...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deluxe Espresso Machine with Integrated Milk F...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Running Shoes with Responsive Cushion...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latest iPhone Pro Max with Triple-Camera Syste...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Next-Gen Gaming Console with 4K Graphics and E...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210824</th>\n",
       "      <td>ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210825</th>\n",
       "      <td>So you’re telling me Emmanuel Macron was groom...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210826</th>\n",
       "      <td>My wife regularly beats me, I get dirty slaps ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210827</th>\n",
       "      <td>Me: Hey babe! Police officer boyfriend: is tha...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210828</th>\n",
       "      <td>“I will take accountability if you think it’s ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210829 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Name of Product Is Accepted Policy\n",
       "0       Ultra-Thin Gaming Laptop with RGB Backlit Keyb...                Yes\n",
       "1       Deluxe Espresso Machine with Integrated Milk F...                Yes\n",
       "2       Advanced Running Shoes with Responsive Cushion...                Yes\n",
       "3       Latest iPhone Pro Max with Triple-Camera Syste...                Yes\n",
       "4       Next-Gen Gaming Console with 4K Graphics and E...                Yes\n",
       "...                                                   ...                ...\n",
       "210824  ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...                 No\n",
       "210825  So you’re telling me Emmanuel Macron was groom...                 No\n",
       "210826  My wife regularly beats me, I get dirty slaps ...                 No\n",
       "210827  Me: Hey babe! Police officer boyfriend: is tha...                 No\n",
       "210828  “I will take accountability if you think it’s ...                 No\n",
       "\n",
       "[210829 rows x 2 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d57f6",
   "metadata": {},
   "source": [
    "## describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e1e10c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210829</td>\n",
       "      <td>210829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>87996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Slim Fit Casual Shirt</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2172</td>\n",
       "      <td>169503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name of Product Is Accepted Policy\n",
       "count                  210829             210829\n",
       "unique                  87996                  3\n",
       "top     Slim Fit Casual Shirt                Yes\n",
       "freq                     2172             169503"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "13470685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in Is Accepted Policy ['Yes' 'No' 'Is Accepted Policy']\n"
     ]
    }
   ],
   "source": [
    "print(\"unique values in Is Accepted Policy\",data[\"Is Accepted Policy\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "693e4bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data with No in Is Accepted Policy 41317\n",
      "the data with Yes in Is Accepted Policy 169503\n"
     ]
    }
   ],
   "source": [
    "print('the data with No in Is Accepted Policy',len(data[data[\"Is Accepted Policy\"]==\"No\"]))\n",
    "print('the data with Yes in Is Accepted Policy',len(data[data[\"Is Accepted Policy\"]==\"Yes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6465e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## delete all data with Accepted Policy = \"Is Accepted Policy\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "aec86592",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Is Accepted Policy\"]!=\"Is Accepted Policy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bd19374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in Is Accepted Policy ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "print(\"unique values in Is Accepted Policy\",data[\"Is Accepted Policy\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c059c75",
   "metadata": {},
   "source": [
    "## add new column describe the prodact policy state numericly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cb480581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_12964\\251259690.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:,\"agree value\"] = data['Is Accepted Policy'].apply(lambda x: 1 if str(x) == \"Yes\" else 0)\n"
     ]
    }
   ],
   "source": [
    "data.loc[:,\"agree value\"] = data['Is Accepted Policy'].apply(lambda x: 1 if str(x) == \"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3603f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "      <th>agree value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra-Thin Gaming Laptop with RGB Backlit Keyb...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deluxe Espresso Machine with Integrated Milk F...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Running Shoes with Responsive Cushion...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latest iPhone Pro Max with Triple-Camera Syste...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Next-Gen Gaming Console with 4K Graphics and E...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Captivating Romantic Novel Set in the Enchanti...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Realistic Toy Sniper Rifle for Outdoor Shootin...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breathtaking Action Movie Marathon in 4K Ultra...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Organic Herbal Infusion Collection for Relaxat...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smart Fitness Tracker with ECG and Blood Oxyge...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name of Product Is Accepted Policy  \\\n",
       "0  Ultra-Thin Gaming Laptop with RGB Backlit Keyb...                Yes   \n",
       "1  Deluxe Espresso Machine with Integrated Milk F...                Yes   \n",
       "2  Advanced Running Shoes with Responsive Cushion...                Yes   \n",
       "3  Latest iPhone Pro Max with Triple-Camera Syste...                Yes   \n",
       "4  Next-Gen Gaming Console with 4K Graphics and E...                Yes   \n",
       "5  Captivating Romantic Novel Set in the Enchanti...                 No   \n",
       "6  Realistic Toy Sniper Rifle for Outdoor Shootin...                 No   \n",
       "7  Breathtaking Action Movie Marathon in 4K Ultra...                Yes   \n",
       "8  Organic Herbal Infusion Collection for Relaxat...                 No   \n",
       "9  Smart Fitness Tracker with ECG and Blood Oxyge...                Yes   \n",
       "\n",
       "   agree value  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            0  \n",
       "6            0  \n",
       "7            1  \n",
       "8            0  \n",
       "9            1  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bf470",
   "metadata": {},
   "source": [
    "## show deplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2993c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all titles of products 210820\n"
     ]
    }
   ],
   "source": [
    "print(\"all titles of products\",len(data['Name of Product']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c0ff541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique titles of product 87995\n"
     ]
    }
   ],
   "source": [
    "print('unique titles of product',len(data['Name of Product'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "49a3afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have 122825 repeted value\n"
     ]
    }
   ],
   "source": [
    "print(\"i have\" ,len(data['Name of Product']) - len(data['Name of Product'].unique()), 'repeted value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5c66cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Home Gym Equipment Set for Total Body Fitness\n",
      "Comprehensive Home Gym Equipment Set for Total Body Fitness\n"
     ]
    }
   ],
   "source": [
    "print(list(data['Name of Product'])[355])\n",
    "print(list(data['Name of Product'])[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5b6b3",
   "metadata": {},
   "source": [
    "## delete all repeted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c5f0c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after removing duplicates: 87995\n"
     ]
    }
   ],
   "source": [
    "data_no_duplicates = data.drop_duplicates(subset='Name of Product', keep='first')\n",
    "# Print the length of the new DataFrame to confirm the removal of duplicates\n",
    "print(\"Length after removing duplicates:\", len(data_no_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a149c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9ee3c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data with No in Is Accepted Policy 40684\n",
      "the data with Yes in Is Accepted Policy 47311\n"
     ]
    }
   ],
   "source": [
    "print('the data with No in Is Accepted Policy',len(data[data[\"Is Accepted Policy\"]==\"No\"]))\n",
    "print('the data with Yes in Is Accepted Policy',len(data[data[\"Is Accepted Policy\"]==\"Yes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6925b9",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80d506",
   "metadata": {},
   "source": [
    "## create stemmer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "83996976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')  # Download the punkt tokenizer if you haven't already\n",
    "\n",
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    stemmed_text = ' '.join(stemmed_tokens)\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030fa4af",
   "metadata": {},
   "source": [
    "## stemme all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0d90601d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Product</th>\n",
       "      <th>Is Accepted Policy</th>\n",
       "      <th>agree value</th>\n",
       "      <th>StemmedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra-Thin Gaming Laptop with RGB Backlit Keyb...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>ultra-thin game laptop with rgb backlit keyboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deluxe Espresso Machine with Integrated Milk F...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>delux espresso machin with integr milk frother...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Running Shoes with Responsive Cushion...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>advanc run shoe with respons cushion for optim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latest iPhone Pro Max with Triple-Camera Syste...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>latest iphon pro max with triple-camera system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Next-Gen Gaming Console with 4K Graphics and E...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>next-gen game consol with 4k graphic and exclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210824</th>\n",
       "      <td>ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>entri 1299 : 21f . 23m , bf ’ s cousin . got d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210825</th>\n",
       "      <td>So you’re telling me Emmanuel Macron was groom...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>so you ’ re tell me emmanuel macron wa groom ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210826</th>\n",
       "      <td>My wife regularly beats me, I get dirty slaps ...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>my wife regularli beat me , i get dirti slap –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210827</th>\n",
       "      <td>Me: Hey babe! Police officer boyfriend: is tha...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>me : hey babe ! polic offic boyfriend : is tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210828</th>\n",
       "      <td>“I will take accountability if you think it’s ...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>“ i will take account if you think it ’ s ok f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87995 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Name of Product Is Accepted Policy  \\\n",
       "0       Ultra-Thin Gaming Laptop with RGB Backlit Keyb...                Yes   \n",
       "1       Deluxe Espresso Machine with Integrated Milk F...                Yes   \n",
       "2       Advanced Running Shoes with Responsive Cushion...                Yes   \n",
       "3       Latest iPhone Pro Max with Triple-Camera Syste...                Yes   \n",
       "4       Next-Gen Gaming Console with 4K Graphics and E...                Yes   \n",
       "...                                                   ...                ...   \n",
       "210824  ENTRY 1299: 21F. 23M, BF’s cousin. Got drunk o...                 No   \n",
       "210825  So you’re telling me Emmanuel Macron was groom...                 No   \n",
       "210826  My wife regularly beats me, I get dirty slaps ...                 No   \n",
       "210827  Me: Hey babe! Police officer boyfriend: is tha...                 No   \n",
       "210828  “I will take accountability if you think it’s ...                 No   \n",
       "\n",
       "        agree value                                        StemmedText  \n",
       "0                 1  ultra-thin game laptop with rgb backlit keyboa...  \n",
       "1                 1  delux espresso machin with integr milk frother...  \n",
       "2                 1  advanc run shoe with respons cushion for optim...  \n",
       "3                 1  latest iphon pro max with triple-camera system...  \n",
       "4                 1  next-gen game consol with 4k graphic and exclu...  \n",
       "...             ...                                                ...  \n",
       "210824            0  entri 1299 : 21f . 23m , bf ’ s cousin . got d...  \n",
       "210825            0  so you ’ re tell me emmanuel macron wa groom ,...  \n",
       "210826            0  my wife regularli beat me , i get dirti slap –...  \n",
       "210827            0  me : hey babe ! polic offic boyfriend : is tha...  \n",
       "210828            0  “ i will take account if you think it ’ s ok f...  \n",
       "\n",
       "[87995 rows x 4 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['StemmedText'] = data['Name of Product'].apply(stem_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876120a",
   "metadata": {},
   "source": [
    "## Tokenize Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c7009560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37917 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "texts = data['StemmedText'].tolist()\n",
    "labels = data['agree value'].tolist()\n",
    "MAX_NUM_WORDS=280\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7094314",
   "metadata": {},
   "source": [
    "## select the fixed-length input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8c729038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  20,   5, 228],\n",
       "       [  0,   0,   0, ...,   0,  20,   5],\n",
       "       [  0,   0,   0, ...,   0,  20,  18],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  42,  65, 153],\n",
       "       [  0,   0,   0, ..., 110, 165, 231],\n",
       "       [ 33,  16, 104, ...,  38, 129,  45]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa6eefc",
   "metadata": {},
   "source": [
    "## categorize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a7d35609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5d86a988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165941b1",
   "metadata": {},
   "source": [
    "## split data to train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "61035a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292e5d6",
   "metadata": {},
   "source": [
    "# Create our LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "950885b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b40ddff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 30, 128)           35840     \n",
      "                                                                 \n",
      " spatial_dropout1d_4 (Spatia  (None, 30, 128)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 196)               254800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,034\n",
      "Trainable params: 291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, embed_dim, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "44bf2e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1843/1843 [==============================] - 1771s 955ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.0301 - val_accuracy: 0.9916\n",
      "Epoch 2/5\n",
      "1843/1843 [==============================] - 1609s 873ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.0286 - val_accuracy: 0.9921\n",
      "Epoch 3/5\n",
      "1843/1843 [==============================] - 937s 508ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0282 - val_accuracy: 0.9916\n",
      "Epoch 4/5\n",
      "1843/1843 [==============================] - 942s 511ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0291 - val_accuracy: 0.9919\n",
      "Epoch 5/5\n",
      "1843/1843 [==============================] - 952s 516ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0283 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2712e3ab700>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8ac3b",
   "metadata": {},
   "source": [
    "## Transform Extracted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b23cd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_legend = {'No': 0, 'Yes': 1}\n",
    "labels_legend_inverted = {f\"{v}\":k for k,v in labels_legend.items()}\n",
    "\n",
    "training_data = {\n",
    "    'max_words':MAX_SEQUENCE_LENGTH,# MAX_NUM_WORDS,\n",
    "    'max_sequence': MAX_SEQUENCE_LENGTH,\n",
    "    'legend': labels_legend,\n",
    "    'labels_legend_inverted': labels_legend_inverted,\n",
    "}\n",
    "\n",
    "labels_legend_inverted = training_data['labels_legend_inverted']\n",
    "legend = training_data['legend']\n",
    "max_sequence = training_data['max_sequence']\n",
    "max_words = training_data['max_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246567fe",
   "metadata": {},
   "source": [
    "## Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d27f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def predict(text_str, max_sequence=280, tokenizer=None, model=None, labels_legend_inverted=None):\n",
    "    if not tokenizer or not model or not labels_legend_inverted:\n",
    "        return None\n",
    "    \n",
    "    #stemming the input text\n",
    "    text_str = stem_text(text_str)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    sequences = tokenizer.texts_to_sequences([text_str])\n",
    "    \n",
    "    # Pad the sequence\n",
    "    x_input = pad_sequences(sequences, maxlen=max_sequence)\n",
    "    \n",
    "    # Predict using the model\n",
    "    y_output = model.predict(x_input,verbose=0)\n",
    "    \n",
    "    # Assuming you want to get the label with the highest probability\n",
    "    top_y_index = np.argmax(y_output, axis=-1)[0]\n",
    "    preds = y_output[0][top_y_index]\n",
    "    \n",
    "    labeled_preds = {labels_legend_inverted[str(top_y_index)]: float(preds)}\n",
    "    \n",
    "    return labels_legend_inverted[str(top_y_index)],labeled_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "cb671007",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best drugs 5ml --------------> No {'No': 0.9997128844261169}\n",
      "gun to kill your enemy --------------> No {'No': 0.9370914101600647}\n",
      "fuck you --------------> No {'No': 0.5841463804244995}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "msg=\"best drugs 5ml\"\n",
    "y_pred,prediction = predict(msg ,max_sequence=max_sequence, tokenizer=tokenizer, model=model, labels_legend_inverted=labels_legend_inverted)\n",
    "print(msg,'-------------->',y_pred,prediction)\n",
    "\n",
    "\n",
    "msg=\"gun to kill your enemy\"\n",
    "y_pred,prediction = predict(msg ,max_sequence=max_sequence, tokenizer=tokenizer, model=model, labels_legend_inverted=labels_legend_inverted)\n",
    "print(msg,'-------------->',y_pred,prediction)\n",
    "\n",
    "msg=\"\"\n",
    "y_pred,prediction = predict(msg ,max_sequence=max_sequence, tokenizer=tokenizer, model=model, labels_legend_inverted=labels_legend_inverted)\n",
    "print(msg,'-------------->',y_pred,prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14c9dd",
   "metadata": {},
   "source": [
    "## test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6be99fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[\"Name of Product\"].tolist()\n",
    "y = data[\"Is Accepted Policy\"].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b931771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x00000270824DEAF0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\weakref.py\", line 371, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [305]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m false \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test)):\n\u001b[1;32m----> 4\u001b[0m     y_pred,prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_legend_inverted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_legend_inverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_test[i] \u001b[38;5;241m==\u001b[39m y_pred:\n\u001b[0;32m      7\u001b[0m         true \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[1;32mIn [302]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(text_str, max_sequence, tokenizer, model, labels_legend_inverted)\u001b[0m\n\u001b[0;32m     15\u001b[0m x_input \u001b[38;5;241m=\u001b[39m pad_sequences(sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_sequence)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m y_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Assuming you want to get the label with the highest probability\u001b[39;00m\n\u001b[0;32m     21\u001b[0m top_y_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:2350\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2349\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2350\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2352\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "true = 0\n",
    "false = 0\n",
    "for i in range(len(X_test)):\n",
    "    y_pred,prediction = predict(X_test[i], tokenizer=tokenizer, model=model, labels_legend_inverted=labels_legend_inverted)\n",
    "\n",
    "    if y_test[i] == y_pred:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1c2b66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true :  12\n",
      "false :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"true : \",true)\n",
    "print(\"false : \",false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True :\",f'{100*true/(true+false):.2f}%')\n",
    "print(\"False :\",f'{100*false/(true+false):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e7a4d",
   "metadata": {},
   "source": [
    "## classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2494aa8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [308]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Predict labels for X_test\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test)):\n\u001b[1;32m---> 15\u001b[0m     y_pred, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_legend_inverted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_legend_inverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     y_pred_binary\u001b[38;5;241m.\u001b[39mappend(convert_labels(y_pred))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate and print classification report\u001b[39;00m\n",
      "Input \u001b[1;32mIn [302]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(text_str, max_sequence, tokenizer, model, labels_legend_inverted)\u001b[0m\n\u001b[0;32m     15\u001b[0m x_input \u001b[38;5;241m=\u001b[39m pad_sequences(sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_sequence)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m y_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Assuming you want to get the label with the highest probability\u001b[39;00m\n\u001b[0;32m     21\u001b[0m top_y_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:2350\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2349\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2350\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2352\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to convert 'Yes' and 'No' to binary labels (1 and 0)\n",
    "def convert_labels(label):\n",
    "    return 1 if label == 'Yes' else 0\n",
    "\n",
    "# Convert 'Is Accepted Policy' to binary labels for y_test\n",
    "y_test_binary = [convert_labels(label) for label in y_test]\n",
    "\n",
    "# Initialize lists to store predicted labels\n",
    "y_pred_binary = []\n",
    "\n",
    "# Predict labels for X_test\n",
    "for i in range(len(X_test)):\n",
    "    y_pred, _ = predict(X_test[i], tokenizer=tokenizer, model=model, labels_legend_inverted=labels_legend_inverted)\n",
    "    y_pred_binary.append(convert_labels(y_pred))\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "adba43b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "4b2e4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53871191",
   "metadata": {},
   "source": [
    "# save all training data in model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e8e0ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485438d",
   "metadata": {},
   "source": [
    "## Save model in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "c113747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{model_folder}/model_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ee5b9",
   "metadata": {},
   "source": [
    "## save dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f666f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3dfe6d",
   "metadata": {},
   "source": [
    "## save the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8cc3a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file_path = f'{model_folder}/training_data.pkl'\n",
    "#save the training_data dictionary using Pickle\n",
    "with open(pickle_file_path, 'wb') as pickle_file:\n",
    "    pickle.dump(training_data, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d0e7c",
   "metadata": {},
   "source": [
    "## save the tokenizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e5ee43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_config = tokenizer.to_json()\n",
    "with open(f'{model_folder}/tokenizer_config.json', 'w') as json_file:\n",
    "    json_file.write(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b0695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
